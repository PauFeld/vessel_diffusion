{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from logging import raiseExceptions\n",
    "from tokenize import Double\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(125)\n",
    "import random\n",
    "random.seed(125)\n",
    "import torch_f as torch_f\n",
    "from modelovae import Node, GRASSEncoder, GRASSDecoder, deserialize\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD Calculation:\n",
    "\n",
    "The function calculate_mmd computes the minimum distance between samples from the real and generated datasets and averages these minimum distances to return the MMD.\n",
    "\n",
    "\n",
    "Coverage Calculation:\n",
    "\n",
    "The function calculate_coverage counts how many real samples have at least one generated sample within a specified threshold and computes the coverage ratio.\n",
    "\n",
    "\n",
    "1-NNA Calculation:\n",
    "\n",
    "The function calculate_1_nna combines both real and generated samples, computes the nearest neighbors, and calculates the accuracy based on how many nearest neighbors match the label of the real samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree(filename, dir):\n",
    "    with open('./' +dir +'/' +filename, \"r\") as f:\n",
    "        byte = f.read() \n",
    "        return byte\n",
    "\n",
    "def numerar_nodos(root, count):\n",
    "    if root is not None:\n",
    "        numerar_nodos(root.left, count)\n",
    "        root.data = len(count)\n",
    "        count.append(1)\n",
    "        numerar_nodos(root.right, count)\n",
    "        return \n",
    "\n",
    "def count_fn(f):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1\n",
    "        return f(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    return wrapper\n",
    "\n",
    "@count_fn\n",
    "def createNode(data, radius,left = None, right = None):\n",
    "        \"\"\"\n",
    "        Utility function to create a node.\n",
    "        \"\"\"\n",
    "        return Node(data, radius, left, right)\n",
    "\n",
    "def count_nodes(self):\n",
    "        \"\"\"Recursively counts the number of nodes in the tree.\"\"\"\n",
    "        count = 1  # Count the current node\n",
    "        if self.left:\n",
    "            count += count_nodes(self.left)  # Count left subtree\n",
    "        if self.right:\n",
    "            count += count_nodes(self.right)  # Count right subtree\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_testing(v, max, decoder, mult, min):\n",
    "    def decode_node(v, max, decoder, mult, min):\n",
    "\n",
    "        cl = decoder.nodeClassifier(v)\n",
    "        _, label = torch.max(cl, 1)\n",
    "        label = label.data\n",
    "        \n",
    "        \n",
    "        if label == 1 and createNode.count <= max:\n",
    "\n",
    "            right, radius = decoder.internalDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius) \n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult, min)\n",
    "            return d\n",
    "\n",
    "        elif label == 2 and createNode.count <= max:\n",
    "\n",
    "            left, right, radius = decoder.bifurcationDecoder(v)\n",
    "                \n",
    "            d = createNode(1, radius)\n",
    "            \n",
    "            d.right = decode_node(right, max, decoder, mult, min)\n",
    "            d.left = decode_node(left, max, decoder, mult, min)\n",
    "        \n",
    "            return d\n",
    "\n",
    "        elif label == 0 : ##output del classifier\n",
    "     \n",
    "            if createNode.count>min:\n",
    "                #print(\"mayor que min\")\n",
    "                radio = decoder.featureDecoder(v)\n",
    "                return createNode(1,radio)\n",
    "        \n",
    "            else:\n",
    "                #print(\"menor que min\")\n",
    "                right, radius = decoder.internalDecoder(v)\n",
    "                d = createNode(1, radius) \n",
    "                d.right = decode_node(right, max, decoder, mult, min)\n",
    "                return d\n",
    "\n",
    "        '''\n",
    "        elif label == 0 : ##output del classifier\n",
    "            print(\"0\", createNode.count)\n",
    "            radio = decoder.featureDecoder(v)\n",
    "            return createNode(1,radio)  \n",
    "        '''\n",
    "\n",
    "    createNode.count = 0\n",
    "    v = decoder.sample_decoder(v)\n",
    "    dec = decode_node (v, max, decoder, mult, min)\n",
    "\n",
    "    return dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "def extract_node_features(tree):\n",
    "    features = []\n",
    "\n",
    "    def traverse(node):\n",
    "        if node is not None:\n",
    "            # Assuming node.radius is a list or array-like with [x, y, z, r]\n",
    "            features.append(node.radius.cpu())\n",
    "            traverse(node.left)\n",
    "            traverse(node.right)\n",
    "\n",
    "    traverse(tree)\n",
    "    return np.array(features)\n",
    "\n",
    "def calculate_mmd_trees(real_trees, generated_trees):\n",
    "    # Extract features from each tree\n",
    "    real_features = [torch.tensor(extract_node_features(tree), dtype=torch.float32).view(-1, 4)[:3] for tree in real_trees]\n",
    "    generated_features = [torch.tensor(tree, dtype=torch.float32).view(-1, 4)[:3] for tree in generated_trees]\n",
    "    chamfer_distances = []\n",
    "    \n",
    "    # Iterate over each generated tree\n",
    "    for g_features in generated_features:\n",
    "        g_features = g_features.view(-1, 4)[:3]  # Reshape to ensure correct dimensions\n",
    "        \n",
    "        # Calculate Chamfer Distance from the generated tree to all real trees\n",
    "        distances = []\n",
    "        for r_features in real_features:\n",
    "            r_features = r_features.view(-1, 4)[:3]  # Reshape real features\n",
    "            dist, _ = chamfer_distance(g_features.unsqueeze(0), r_features.unsqueeze(0))\n",
    "            distances.append(dist.item())\n",
    "        \n",
    "        # Take the minimum distance across all real trees\n",
    "        chamfer_distances.append(min(distances))\n",
    "\n",
    "    # Average Chamfer Distance over all generated trees\n",
    "    mmd_value = torch.mean(torch.tensor(chamfer_distances)).item()\n",
    "    \n",
    "    return mmd_value\n",
    "\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import torch\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "def calculate_coverage(real_trees, generated_trees):\n",
    "    \"\"\"\n",
    "    Calculate the Coverage (COV) between real and generated trees using Chamfer Distance.\n",
    "    \n",
    "    Parameters:\n",
    "    - real_trees: List of original trees (reference set).\n",
    "    - generated_trees: List of generated trees (target set).\n",
    "    \n",
    "    Returns:\n",
    "    - coverage: Fraction of real trees matched by generated trees.\n",
    "    \"\"\"\n",
    "    # Convert features for real and generated trees into tensors\n",
    "    real_features = [torch.tensor(extract_node_features(tree), dtype=torch.float32).view(-1, 4)[:3] for tree in real_trees]\n",
    "    generated_features = [torch.tensor(tree, dtype=torch.float32).view(-1, 4)[:3] for tree in generated_trees]\n",
    "\n",
    "    # Track matched real trees\n",
    "    matched_real_trees = set()\n",
    "\n",
    "    # Iterate over each generated tree\n",
    "    for g_features in generated_features:\n",
    "        min_distances = []\n",
    "        # Calculate Chamfer Distance to all real trees\n",
    "        for idx, r_features in enumerate(real_features):\n",
    "            dist, _ = chamfer_distance(g_features.unsqueeze(0), r_features.unsqueeze(0))\n",
    "            min_distances.append((dist.item(), idx))\n",
    "\n",
    "        # Find the nearest real tree\n",
    "        nearest_real_tree_idx = min(min_distances, key=lambda x: x[0])[1]\n",
    "        matched_real_trees.add(nearest_real_tree_idx)\n",
    "\n",
    "    # Calculate coverage\n",
    "    coverage = len(matched_real_trees) / len(real_trees)\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "def calculate_1_nna(real_trees, generated_trees):\n",
    "    \"\"\"\n",
    "    Calculate the 1-Nearest Neighbor Accuracy (1-NNA) between real and generated trees.\n",
    "    \n",
    "    Parameters:\n",
    "    - real_trees: List of original trees (reference set).\n",
    "    - generated_trees: List of generated trees (target set).\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: 1-NNA accuracy score.\n",
    "    \"\"\"\n",
    "    # Extract features for real and generated trees\n",
    "    real_features = [torch.tensor(extract_node_features(tree), dtype=torch.float32).view(-1, 4)[:3] for tree in real_trees]\n",
    "    generated_features = [torch.tensor(tree, dtype=torch.float32).view(-1, 4)[:3] for tree in generated_trees]\n",
    "\n",
    "    # Concatenate the features\n",
    "    combined_features = real_features + generated_features\n",
    "    labels = [0] * len(real_trees) + [1] * len(generated_trees)\n",
    "\n",
    "    correct = 0\n",
    "    total_samples = len(combined_features)\n",
    "\n",
    "    # Perform leave-one-out nearest neighbor classification\n",
    "    for i, feature in enumerate(combined_features):\n",
    "        # Exclude the current feature from the comparison\n",
    "        other_features = combined_features[:i] + combined_features[i+1:]\n",
    "        other_labels = labels[:i] + labels[i+1:]\n",
    "\n",
    "        # Calculate Chamfer distances to all other features\n",
    "        distances = [chamfer_distance(feature.unsqueeze(0), other_feature.unsqueeze(0))[0].item() for other_feature in other_features]\n",
    "\n",
    "        # Find the nearest neighbor's label\n",
    "        nearest_neighbor_index = distances.index(min(distances))\n",
    "        nearest_label = other_labels[nearest_neighbor_index]\n",
    "\n",
    "        # Check if the nearest neighbor is from the opposite set\n",
    "        if nearest_label != labels[i]:\n",
    "            correct += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct / total_samples\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    return batch\n",
    "\n",
    "\n",
    "class tDataset(Dataset):\n",
    "    def __init__(self, l, dir, transform=None):\n",
    "        self.names = l\n",
    "        self.transform = transform\n",
    "        self.data = [] #lista con las strings de todos los arboles\n",
    "        for file in self.names:\n",
    "            self.data.append(read_tree(file, dir))\n",
    "        self.trees = []\n",
    "\n",
    "        for tree in self.data:\n",
    "            deserial = deserialize(tree)\n",
    "            self.trees.append(deserial)\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #file = self.names[idx]\n",
    "        #string = read_tree(file)\n",
    "        tree = self.trees[idx]\n",
    "        name = self.names[idx]\n",
    "        return tree\n",
    "\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_evaluate(real_dataset, n_samples):\n",
    "    real_trees = real_dataset.trees\n",
    "    generated_trees = []\n",
    "    # Generate synthetic samples\n",
    "    with torch.no_grad():\n",
    "        generated_trees = np.load(\"generados/intra/set1.npy\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    mmd = calculate_mmd_trees(real_trees, generated_trees)\n",
    "    coverage = calculate_coverage(real_trees, generated_trees)\n",
    "    accuracy = calculate_1_nna(real_trees, generated_trees)\n",
    "\n",
    "    return mmd, coverage, accuracy #, coverage, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Matching Distance (MMD): 0.28847965598106384\n",
      "Coverage (COV): 0.04\n",
      "1-Nearest Neighbor Accuracy (1-NNA): 0.00\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Intra\"  # Replace with your dataset name\n",
    "p = str(10)\n",
    "eps = str(0)+str(2)\n",
    "d = dataset_name + \"P\" +p + \"eps\" + eps\n",
    "file_list = os.listdir(d)[:100]\n",
    " \n",
    "#data_loader = DataLoader(dataset, batch_size = batch_size, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "# Create dataset\n",
    "real_dataset = tDataset(file_list, d)\n",
    "'''\n",
    "# Initialize decoder\n",
    "a = [1., 1., 1.]\n",
    "mult = torch.Tensor(a).to(device)\n",
    "latent_size = 64\n",
    "Grassdecoder = GRASSDecoder(latent_size=latent_size, hidden_size=256, mult=mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "Grassdecoder.eval()\n",
    "#checkpoint = torch.load(\"output/modelosentrenadosMedIA/\" + dataset_name + \"P\" +p + \"eps\" + eps+ \"-best.pth\")\n",
    "Grassdecoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "'''\n",
    "\n",
    "# Generate synthetic trees and evaluate\n",
    "n_samples = 100\n",
    "threshold = 1.5  # Adjust as necessary\n",
    "mmd, coverage, accuracy = generate_and_evaluate(real_dataset, n_samples)\n",
    "\n",
    "# Print results\n",
    "print(f\"Minimum Matching Distance (MMD): {mmd}\")\n",
    "print(f\"Coverage (COV): {coverage:.2f}\")\n",
    "print(f\"1-Nearest Neighbor Accuracy (1-NNA): {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evaluation_metrics_3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevaluation_metrics_3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgan_mmd_cov\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pairwise_EMD_CD_trees\u001b[39m(ref_trees, sample_trees, batch_size):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluation_metrics_3d'"
     ]
    }
   ],
   "source": [
    "from evaluation_metrics_3d import lgan_mmd_cov\n",
    "\n",
    "import torch\n",
    "\n",
    "def _pairwise_EMD_CD_trees(ref_trees, sample_trees, batch_size):\n",
    "    \"\"\"\n",
    "    Compute the pairwise Earth Mover's Distance (EMD) and Chamfer Distance (CD) between\n",
    "    reference and sample trees.\n",
    "\n",
    "    Args:\n",
    "    - ref_trees (list[Node]): List of reference trees (real data).\n",
    "    - sample_trees (list[Node]): List of sample trees (synthetic data).\n",
    "    - batch_size (int): Batch size for computations.\n",
    "\n",
    "    Returns:\n",
    "    - M_rs_cd (torch.Tensor): Pairwise Chamfer Distance matrix.\n",
    "    - M_rs_emd (torch.Tensor): Pairwise Earth Mover's Distance matrix.\n",
    "    \"\"\"\n",
    "    num_ref, num_sample = len(ref_trees), len(sample_trees)\n",
    "    M_rs_cd = torch.zeros((num_ref, num_sample))\n",
    "    M_rs_emd = torch.zeros((num_ref, num_sample))\n",
    "\n",
    "    for i, ref_tree in enumerate(ref_trees):\n",
    "        for j, sample_tree in enumerate(sample_trees):\n",
    "            # Calculate Chamfer Distance between the reference and sample tree\n",
    "            M_rs_cd[i, j] = compute_chamfer_distance(ref_tree, sample_tree)\n",
    "\n",
    "            # Calculate Earth Mover's Distance between the reference and sample tree\n",
    "            M_rs_emd[i, j] = compute_earth_mover_distance(ref_tree, sample_tree)\n",
    "\n",
    "    return M_rs_cd, M_rs_emd\n",
    "\n",
    "def compute_chamfer_distance(tree1, tree2):\n",
    "    \"\"\"\n",
    "    Compute Chamfer Distance (CD) between two trees.\n",
    "\n",
    "    Args:\n",
    "    - tree1 (Node): Root node of the first tree.\n",
    "    - tree2 (Node): Root node of the second tree.\n",
    "\n",
    "    Returns:\n",
    "    - cd (float): Chamfer Distance between the two trees.\n",
    "    \"\"\"\n",
    "    nodes1 = extract_tree_nodes(tree1)\n",
    "    nodes2 = extract_tree_nodes(tree2)\n",
    "\n",
    "    # Calculate distance from each node in nodes1 to the closest node in nodes2\n",
    "\n",
    "    dist1 = torch.tensor([min(torch.norm(n1.radius[:3] - n2.radius[0][:3]).item() for n2 in nodes2) for n1 in nodes1])\n",
    "\n",
    "    # Calculate distance from each node in nodes2 to the closest node in nodes1\n",
    "    dist2 = torch.tensor([min(torch.norm(n2.radius[0][:3] - n1.radius[:3]).item() for n1 in nodes1) for n2 in nodes2])\n",
    "\n",
    "    # Chamfer Distance is the mean of these closest distances\n",
    "    cd = (dist1.mean() + dist2.mean()).item()\n",
    "    return cd\n",
    "\n",
    "def compute_earth_mover_distance(tree1, tree2):\n",
    "    \"\"\"\n",
    "    Compute Earth Mover's Distance (EMD) between two trees.\n",
    "\n",
    "    Args:\n",
    "    - tree1 (Node): Root node of the first tree.\n",
    "    - tree2 (Node): Root node of the second tree.\n",
    "\n",
    "    Returns:\n",
    "    - emd (float): Earth Mover's Distance between the two trees.\n",
    "    \"\"\"\n",
    "    nodes1 = extract_tree_nodes(tree1)\n",
    "    nodes2 = extract_tree_nodes(tree2)\n",
    "\n",
    "    # Calculate EMD as the sum of distances of corresponding nodes\n",
    "    emd_distances = [torch.norm(n1.radius[:3] - n2.radius[0][:3]).item() for n1, n2 in zip(nodes1, nodes2)]\n",
    "    emd = sum(emd_distances) / len(emd_distances) if emd_distances else 0.0\n",
    "    return emd\n",
    "\n",
    "def extract_tree_nodes(root):\n",
    "    \"\"\"\n",
    "    Extract all nodes from a binary tree using breadth-first traversal.\n",
    "\n",
    "    Args:\n",
    "    - root (Node): Root node of the tree.\n",
    "\n",
    "    Returns:\n",
    "    - nodes (list[Node]): List of all nodes in the tree.\n",
    "    \"\"\"\n",
    "    nodes = []\n",
    "    queue = [root]\n",
    "    while queue:\n",
    "        current = queue.pop(0)\n",
    "        nodes.append(current)\n",
    "        \n",
    "        # Enqueue left and right children if they exist\n",
    "        if current.left is not None:\n",
    "            queue.append(current.left)\n",
    "        if current.right is not None:\n",
    "            queue.append(current.right)\n",
    "    \n",
    "    return nodes\n",
    "\n",
    "import torch\n",
    "\n",
    "def knn_trees(M_real_real, M_real_synth, M_synth_synth, k=1, sqrt=False):\n",
    "    \"\"\"\n",
    "    Computes the 1-Nearest Neighbor accuracy using precomputed pairwise distances.\n",
    "\n",
    "    Args:\n",
    "    - M_real_real (torch.Tensor): Pairwise distance matrix between real trees (N_real x N_real).\n",
    "    - M_real_synth (torch.Tensor): Pairwise distance matrix between real and synthetic trees (N_real x N_synth).\n",
    "    - M_synth_synth (torch.Tensor): Pairwise distance matrix between synthetic trees (N_synth x N_synth).\n",
    "    - k (int): Number of neighbors to consider.\n",
    "    - sqrt (bool): If True, will take the square root of distances to return to original units.\n",
    "\n",
    "    Returns:\n",
    "    - results (dict): Dictionary with 1-NN accuracy.\n",
    "    \"\"\"\n",
    "    if sqrt:\n",
    "        M_real_real = torch.sqrt(M_real_real)\n",
    "        M_real_synth = torch.sqrt(M_real_synth)\n",
    "        M_synth_synth = torch.sqrt(M_synth_synth)\n",
    "    \n",
    "    # 1-NN accuracy calculation\n",
    "    N_real = M_real_synth.size(0)\n",
    "    N_synth = M_real_synth.size(1)\n",
    "    \n",
    "    # Concatenate distances between real and synthetic trees\n",
    "    distances = torch.cat((M_real_real, M_real_synth), dim=1)\n",
    "    correct = 0\n",
    "\n",
    "    # For each synthetic tree, find the nearest neighbor among real trees\n",
    "    for i in range(N_synth):\n",
    "        nn_index = torch.argmin(M_real_synth[:, i])  # Nearest real tree index for each synthetic tree\n",
    "        if nn_index < N_real:  # If the nearest neighbor is among real trees\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / float(N_synth)\n",
    "    return {\"acc\": accuracy}\n",
    "\n",
    "\n",
    "def compute_all_metrics_trees(sample_trees, ref_trees, batch_size, logger):\n",
    "    \"\"\"\n",
    "    Computes Minimum Matching Distance (MMD), Coverage, and 1-Nearest Neighbor Accuracy metrics\n",
    "    between sample (synthetic) and reference (real) trees.\n",
    "    \n",
    "    Args:\n",
    "    - sample_trees (list[Node]): Generated synthetic trees.\n",
    "    - ref_trees (list[Node]): Real trees from the dataset.\n",
    "    - batch_size (int): Batch size for metric computation.\n",
    "    - logger (tuple): Logger and output directory for saving logs or intermediate results.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: A dictionary containing calculated metrics:\n",
    "      - \"EMD\": Minimum Matching Distance and Coverage metrics for EMD.\n",
    "      - \"CD\": Minimum Matching Distance and Coverage metrics for CD.\n",
    "      - \"1-NN-CD-acc\": 1-Nearest Neighbor Accuracy based on Chamfer Distance.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    logger, orig_trees_dir = logger  # Unpack logger and directory for tree data\n",
    "\n",
    "    print(\"Calculating Pairwise EMD and CD distances...\")\n",
    "    # Compute the pairwise Earth Mover's Distance (EMD) and Chamfer Distance (CD)\n",
    "    M_rs_cd, M_rs_emd = _pairwise_EMD_CD_trees(ref_trees, sample_trees, batch_size)\n",
    "\n",
    "    # Calculate EMD-based metrics\n",
    "    res_emd = lgan_mmd_cov(M_rs_emd.t())\n",
    "    results.update({\n",
    "        \"EMD\": res_emd\n",
    "    })\n",
    "\n",
    "    # Calculate CD-based metrics\n",
    "    res_cd = lgan_mmd_cov(M_rs_cd.t())\n",
    "    results.update({\n",
    "        \"CD\": res_cd\n",
    "    })\n",
    "\n",
    "    # Print each metric for verification\n",
    "    for metric, value in results.items():\n",
    "        print(f\"[{metric}] {value}\")\n",
    "\n",
    "    # Calculate 1-Nearest Neighbor (1-NN) Accuracy using Chamfer Distance\n",
    "    print(\"Calculating 1-Nearest Neighbor Accuracy (1-NN-CD)...\")\n",
    "    one_nn_cd_res = knn_trees(M_rs_cd, M_rs_cd, M_rs_cd, 1, sqrt=False)\n",
    "    results.update(\n",
    "        {\"1-NN-CD-acc\": one_nn_cd_res[\"acc\"]}  # Assumes \"acc\" key contains 1-NN accuracy\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/paper/IntraP10eps01'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/paper/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mP\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124meps\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m file_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Create dataset\u001b[39;00m\n\u001b[1;32m     37\u001b[0m real_dataset \u001b[38;5;241m=\u001b[39m tDataset(file_list, d)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/paper/IntraP10eps01'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "# Assuming other necessary imports like the GRASSDecoder and any helper functions\n",
    "\n",
    "def generate_and_evaluate(real_dataset, n_samples, latent_size, decoder, mult, threshold, batch_size, logger):\n",
    "    # Extract real trees from the dataset\n",
    "    real_trees = real_dataset.trees  # Adjust based on how tDataset stores trees\n",
    "    generated_trees = []\n",
    "\n",
    "    # Generate synthetic trees\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            noise = torch.randn(1, latent_size).to(device)  # Batch size of 1 per generated sample\n",
    "            generated_tree = decode_testing(noise, 200, decoder, mult, 20)  # Generate a synthetic tree\n",
    "            count = []\n",
    "            numerar_nodos(generated_tree, count)  # Ensure nodes are correctly numbered\n",
    "            generated_trees.append(generated_tree)\n",
    "\n",
    "    # Calculate metrics\n",
    "    results = compute_all_metrics_trees(generated_trees, real_trees, batch_size, logger)\n",
    "\n",
    "    # Extract individual metrics from the results dictionary\n",
    "    mmd = results['EMD']['lgan_mmd']  # Minimum Matching Distance\n",
    "    coverage = results['EMD']['lgan_cov']  # Coverage\n",
    "    accuracy = results.get(\"1-NN-CD-acc\", 0.0)  # 1-Nearest Neighbor Accuracy, default to 0 if missing\n",
    "\n",
    "    return mmd, coverage, accuracy\n",
    "\n",
    "# Main script for generating and evaluating trees\n",
    "dataset_name = \"Intra\"  # Replace with your dataset name\n",
    "p = str(10)\n",
    "eps = str(0) + str(1)\n",
    "d = f\"data/paper/{dataset_name}P{p}eps{eps}\"\n",
    "file_list = os.listdir(d)[:100]\n",
    "\n",
    "# Create dataset\n",
    "real_dataset = tDataset(file_list, d)\n",
    "\n",
    "# Initialize decoder\n",
    "a = [1., 1., 1.]\n",
    "mult = torch.Tensor(a).to(device)\n",
    "latent_size = 64\n",
    "Grassdecoder = GRASSDecoder(latent_size=latent_size, hidden_size=256, mult=mult)\n",
    "Grassdecoder = Grassdecoder.to(device)\n",
    "Grassdecoder.eval()\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(f\"output/{dataset_name}-best.pth\")\n",
    "Grassdecoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "\n",
    "# Set parameters for generation and evaluation\n",
    "n_samples = 100\n",
    "threshold = 1.5  # Adjust if necessary\n",
    "batch_size = 32  # Set batch size for evaluation\n",
    "logger = (None, \"data/logs/\")  # Adjust logger directory if needed\n",
    "\n",
    "# Generate synthetic trees and calculate metrics\n",
    "mmd, coverage, accuracy = generate_and_evaluate(real_dataset, n_samples, latent_size, Grassdecoder, mult, threshold, batch_size, logger)\n",
    "\n",
    "# Print results\n",
    "print(f\"Minimum Matching Distance (MMD): {mmd}\")\n",
    "print(f\"Coverage (COV): {coverage:.2f}\")\n",
    "print(f\"1-Nearest Neighbor Accuracy (1-NNA): {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
